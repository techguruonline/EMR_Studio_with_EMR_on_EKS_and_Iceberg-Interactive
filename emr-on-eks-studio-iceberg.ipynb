{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14dea296-4b34-4cfa-8323-b758463c25e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Iceberg is a high-performance format for huge analytic tables. Iceberg brings the reliability and simplicity of SQL tables to big data. With ever growing data verity and volume, Data lakes became popular as a centralized repository that allows you to store all structured and unstructured data at any scale. \n",
    "Data lakes suffices the storage requirements and provides analytical capabilities, but doesn’t address the “transactional” requirements like the DML operations, ACID transactions (Atomicity, Consistency,  Isolation, Durability) with concurrent reads and writes uses cases. With consumer privacy laws like GDPR, CCPA bring in more requirements that challenge the traditional designs of the data lake.\n",
    "\n",
    "Apache Iceberg is an Open Table Format that solves the modern data lake challenges and requirements by introducing new capabilities that enable multiple applications to work together on the same data in a transactionally consistent manner and defines additional information on the state of datasets as they evolve and change over time.\n",
    "Apache Iceberg table format offers similar capabilities and functionalities that a traditional RDBMS provides but in a fully open table format so multiple engines like Spark, Trino, Presto can operate on the same dataset. It provides powerful features such as \n",
    "- ACID transaction support for concurrent read and writes, provides transactional consistency between multiple applications with full read isolation and concurrent writes.\n",
    "- Time travel to go back in time, analyze changes to the data between updates, deletes\n",
    "- Rollback to previous version that allows users to quickly correct issues by restoring the correct data at any point in time.\n",
    "- Schema evolution that allows users to add, rename, drop columns without rewriting the underlying data ensuring performance.\n",
    "- Supports multiple file formats like Parquet, ORC, Avro\n",
    "\n",
    "\n",
    "\n",
    "### For additional details, please refer to Apache Iceberg documentation:\n",
    "-  __[EMR Iceberg Documentation](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-iceberg.html)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430bbc6f-4b10-4062-8a24-3a0b34eb2710",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-Requisite:\n",
    "\n",
    "For executing the code in this notebook you will need the below:\n",
    "- A AWS account\n",
    "Below services should be created and configured\n",
    "- EMR Studio\n",
    "- EMR Studio Workspace\n",
    "- EMR on EKS Virtual Cluster\n",
    "- EKS Cluster (EC2 based)\n",
    "- Managed Endpoint\n",
    "- IAM Policy\n",
    "- Application Load Balancer\n",
    "- VPC and Subnet\n",
    "\n",
    "#### <font color=red>Important step for Iceberg to work with EMR Studio (Jupyter Notebook - JUPYTER_ENTERPRISE_GATEWAY) on EMR-on-EKS cluster</font>\n",
    "As Jupyter notebook (attached to EMR-on-EKS) does not support cell magic, we do not have an option to configure Iceberg specific parameters including Iceberg Jars.\n",
    "For this reason we need to configure it as part of the Managed endpoint, below is the config. These are defaults, you can change the values according to your needs for e.g: increase executor.memory from 2G to 4G or 8G whatever you like.\n",
    "\n",
    "\"configurationOverrides\": {\n",
    ">     \"applicationConfiguration\": [\n",
    ">         {\n",
    ">                        \"classification\": \"spark-defaults\",\n",
    "            \"properties\": {\n",
    "                \"spark.executor.memory\": \"2G\",\n",
    "                \"spark.sql.catalog.glue_catalog.io-impl\": \"org.apache.iceberg.aws.s3.S3FileIO\",\n",
    "                \"spark.driver.memory\": \"2G\",\n",
    "                \"spark.kubernetes.executor.request.cores\": \"1.5\",\n",
    "                \"spark.driver.cores\": \"1\",\n",
    "                \"spark.sql.catalogImplementation\": \"hive\",\n",
    "                \"spark.sql.catalog.glue_catalog.catalog-impl\": \"org.apache.iceberg.aws.glue.GlueCatalog\",\n",
    "                \"spark.executor.cores\": \"1\",\n",
    "                \"spark.sql.catalog.glue_catalog.warehouse\": \"s3://<bucket-name>/<folder-name>/\",\n",
    "                \"spark.dynamicAllocation.maxExecutors\": \"20\",\n",
    "                \"spark.sql.catalog.glue_catalog\": \"org.apache.iceberg.spark.SparkCatalog\",\n",
    "                \"spark.dynamicAllocation.shuffleTracking.enabled\": \"true\",\n",
    "                \"spark.dynamicAllocation.shuffleTracking.timeout\": \"300s\",\n",
    "                \"spark.kubernetes.driver.request.cores\": \"0.5\",\n",
    "                \"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "                \"spark.kubernetes.allocation.batch.size\": \"2\",\n",
    "                \"spark.hadoop.hive.metastore.client.factory.class\": \"com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory\",\n",
    "                \"spark.sql.catalog.glue_catalog.lock-impl\": \"org.apache.iceberg.aws.glue.DynamoLockManager\",\n",
    "                \"spark.dynamicAllocation.minExecutors\": \"0\",\n",
    "                \"spark.sql.catalog.glue_catalog.lock.table\": \"myIcebergLockTable\",\n",
    "                \"spark.dynamicAllocation.enabled\": \"true\",\n",
    "                \"spark.dynamicAllocation.executorAllocationRatio\": \"1\",\n",
    "                \"spark.jars\": \"local:///usr/share/aws/iceberg/lib/iceberg-spark3-runtime.jar\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1757884c-cebd-4504-9a87-9661e8b5c24b",
   "metadata": {},
   "source": [
    "### Current Setup used for this notebook\n",
    "\n",
    "EMR version: emr-6.8.0-latest\n",
    "EKS version: 1.21\n",
    "Instance Type for EKS cluster: m5.xlarge\n",
    "No of Instances: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3971e-518f-4eb7-a402-3104e0778b93",
   "metadata": {},
   "source": [
    "## Connect to Glue catalog, check existing databases and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb35b1c-a8fd-497d-9f0b-9ffda7492fd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:07:09.781841Z",
     "iopub.status.busy": "2022-11-09T12:07:09.781415Z",
     "iopub.status.idle": "2022-11-09T12:07:16.264855Z",
     "shell.execute_reply": "2022-11-09T12:07:16.263825Z",
     "shell.execute_reply.started": "2022-11-09T12:07:09.781808Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|db       |\n",
      "|db_ps    |\n",
      "|db_sql   |\n",
      "|default  |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Connect to Glue catalog, check existing databases and tables\n",
    "spark.sql(\"show databases like '*'\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c24abaf-b821-4127-82c7-b6a1b478d921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:07:19.792387Z",
     "iopub.status.busy": "2022-11-09T12:07:19.791898Z",
     "iopub.status.idle": "2022-11-09T12:07:28.858524Z",
     "shell.execute_reply": "2022-11-09T12:07:28.857236Z",
     "shell.execute_reply.started": "2022-11-09T12:07:19.792359Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|default  |customer |false      |\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables in default\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aee50e0a-85d7-436e-a2ac-195ba8e6ee1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:07:39.339938Z",
     "iopub.status.busy": "2022-11-09T12:07:39.339352Z",
     "iopub.status.idle": "2022-11-09T12:07:39.426988Z",
     "shell.execute_reply": "2022-11-09T12:07:39.426162Z",
     "shell.execute_reply.started": "2022-11-09T12:07:39.339893Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|      catalog|namespace|\n",
      "+-------------+---------+\n",
      "|spark_catalog|  default|\n",
      "+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show current namespace\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b6d473a-0e76-4fd9-af24-b2cd718bb487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:08:00.861645Z",
     "iopub.status.busy": "2022-11-09T12:08:00.860956Z",
     "iopub.status.idle": "2022-11-09T12:08:00.881593Z",
     "shell.execute_reply": "2022-11-09T12:08:00.880762Z",
     "shell.execute_reply.started": "2022-11-09T12:08:00.861572Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the current namespace to glue_catalog\n",
    "spark.sql(\"use glue_catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579a92d-5443-46f9-b613-63d76dc5015b",
   "metadata": {},
   "source": [
    "# Create new database and table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99015cff-de86-42f9-9e94-f1e48596522b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:08:05.287772Z",
     "iopub.status.busy": "2022-11-09T12:08:05.287217Z",
     "iopub.status.idle": "2022-11-09T12:08:05.864781Z",
     "shell.execute_reply": "2022-11-09T12:08:05.863518Z",
     "shell.execute_reply.started": "2022-11-09T12:08:05.287738Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new database, at this point you can also open Athena and verify the newly created database\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS iceberg_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "463b6c00-cd78-4ebe-a41d-43d544c30f44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:09:37.804410Z",
     "iopub.status.busy": "2022-11-09T12:09:37.803904Z",
     "iopub.status.idle": "2022-11-09T12:09:37.966092Z",
     "shell.execute_reply": "2022-11-09T12:09:37.964868Z",
     "shell.execute_reply.started": "2022-11-09T12:09:37.804381Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use newly created database as the default database (namespace)\n",
    "spark.sql(\"use iceberg_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a208bd9d-8429-4658-a0ed-bdd85eec050c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:09:40.977174Z",
     "iopub.status.busy": "2022-11-09T12:09:40.976677Z",
     "iopub.status.idle": "2022-11-09T12:09:41.043645Z",
     "shell.execute_reply": "2022-11-09T12:09:41.042249Z",
     "shell.execute_reply.started": "2022-11-09T12:09:40.977144Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|     catalog| namespace|\n",
      "+------------+----------+\n",
      "|glue_catalog|iceberg_db|\n",
      "+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show current namespace and notice now the namespace is \"iceberg_db\" instead of \"NaT\" as displayed earlier\n",
    "spark.sql(\"show current namespace\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "467984d4-1ca7-48ed-ab16-275dfa524f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:09:45.382522Z",
     "iopub.status.busy": "2022-11-09T12:09:45.381505Z",
     "iopub.status.idle": "2022-11-09T12:09:45.575941Z",
     "shell.execute_reply": "2022-11-09T12:09:45.574766Z",
     "shell.execute_reply.started": "2022-11-09T12:09:45.382469Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop table if it exists usign PySpark (drop table just drops the metadata and not the underlying data files)\n",
    "spark.sql(\"DROP TABLE IF EXISTS customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7325f292-8da8-4383-a622-7eac3edbb249",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:09:48.601763Z",
     "iopub.status.busy": "2022-11-09T12:09:48.601278Z",
     "iopub.status.idle": "2022-11-09T12:09:50.807319Z",
     "shell.execute_reply": "2022-11-09T12:09:50.806556Z",
     "shell.execute_reply.started": "2022-11-09T12:09:48.601735Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create table in glue_catalog --> iceberg_db database\n",
    "spark.sql(\" CREATE TABLE IF NOT EXISTS customer (cust_id int, cust_name string, cust_age int, cust_loc string) TBLPROPERTIES('table_type' = 'ICEBERG','format' = 'parquet')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f3332-cb6e-45f3-a09a-a9a7c6436fb9",
   "metadata": {},
   "source": [
    "# DML Operations\n",
    "## INSERT, UPDATE, DELETE records in Iceberg table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f29dc4d-4175-4124-95ca-242039f0c9a1",
   "metadata": {},
   "source": [
    "### INSERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b9279a-aff5-4b4e-844b-96d74aaac759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:09:54.601122Z",
     "iopub.status.busy": "2022-11-09T12:09:54.600614Z",
     "iopub.status.idle": "2022-11-09T12:10:15.417395Z",
     "shell.execute_reply": "2022-11-09T12:10:15.416130Z",
     "shell.execute_reply.started": "2022-11-09T12:09:54.601092Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's insert few records to iceberg table\n",
    "spark.sql(\"INSERT INTO customer VALUES (1,'Prasad Nadig', 25, 'NJ')\")\n",
    "spark.sql(\"INSERT INTO customer VALUES (2,'Ethereum', 80, 'NY')\")\n",
    "spark.sql(\"INSERT INTO customer VALUES (3,'Cosmos', 25, 'PA')\")\n",
    "spark.sql(\"INSERT INTO customer VALUES (4,'Solana', 55, 'MD')\")\n",
    "spark.sql(\"INSERT INTO customer VALUES (5,'Carnado', 15, 'TX')\")\n",
    "spark.sql(\"INSERT INTO customer VALUES (6,'Link', 45, 'NJ')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4628594f-8f0b-42a4-a9d0-1088e4aecc0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:10:45.327963Z",
     "iopub.status.busy": "2022-11-09T12:10:45.326909Z",
     "iopub.status.idle": "2022-11-09T12:10:46.195961Z",
     "shell.execute_reply": "2022-11-09T12:10:46.195151Z",
     "shell.execute_reply.started": "2022-11-09T12:10:45.327906Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------+--------+\n",
      "|cust_id|   cust_name|cust_age|cust_loc|\n",
      "+-------+------------+--------+--------+\n",
      "|      1|Prasad Nadig|      25|      NJ|\n",
      "|      2|    Ethereum|      80|      NY|\n",
      "|      3|      Cosmos|      25|      PA|\n",
      "|      4|      Solana|      55|      MD|\n",
      "|      5|     Carnado|      15|      TX|\n",
      "|      6|        Link|      45|      NJ|\n",
      "+-------+------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify if the insert was successful\n",
    "spark.sql(\"SELECT * FROM customer ORDER BY cust_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494478a9-b924-43f5-a19f-4ffa7d0ecfbd",
   "metadata": {},
   "source": [
    "### UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5204499e-1740-47e5-9263-5d64321c2782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:10:49.985898Z",
     "iopub.status.busy": "2022-11-09T12:10:49.985404Z",
     "iopub.status.idle": "2022-11-09T12:11:17.666213Z",
     "shell.execute_reply": "2022-11-09T12:11:17.665270Z",
     "shell.execute_reply.started": "2022-11-09T12:10:49.985869Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similar to traditional RDBMS, you can issue UPDATE statements to Iceberg tables on Datalakes\n",
    "spark.sql(\"UPDATE customer SET cust_age = 50 WHERE cust_id = 6\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f0d73bf-310a-40c8-bb8e-84ec82766abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:11:21.775972Z",
     "iopub.status.busy": "2022-11-09T12:11:21.775544Z",
     "iopub.status.idle": "2022-11-09T12:11:23.955008Z",
     "shell.execute_reply": "2022-11-09T12:11:23.953927Z",
     "shell.execute_reply.started": "2022-11-09T12:11:21.775941Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------+--------+\n",
      "|cust_id|cust_name|cust_age|cust_loc|\n",
      "+-------+---------+--------+--------+\n",
      "|      6|     Link|      50|      NJ|\n",
      "+-------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verify updates\n",
    "spark.sql(\"SELECT * FROM customer WHERE cust_id = 6 ORDER BY cust_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c137bc-7dec-4409-9f6c-495bf9d61895",
   "metadata": {},
   "source": [
    "### DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4a2e0cc-1ae6-4998-b007-588818d1efa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:11:34.630112Z",
     "iopub.status.busy": "2022-11-09T12:11:34.629608Z",
     "iopub.status.idle": "2022-11-09T12:11:36.656087Z",
     "shell.execute_reply": "2022-11-09T12:11:36.654810Z",
     "shell.execute_reply.started": "2022-11-09T12:11:34.630083Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DELETE FROM customer WHERE cust_id = 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a4803b9-6ce7-436b-bf7c-377fd3d711a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:11:39.930089Z",
     "iopub.status.busy": "2022-11-09T12:11:39.929672Z",
     "iopub.status.idle": "2022-11-09T12:11:40.261204Z",
     "shell.execute_reply": "2022-11-09T12:11:40.260083Z",
     "shell.execute_reply.started": "2022-11-09T12:11:39.930059Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------+--------+\n",
      "|cust_id|cust_name|cust_age|cust_loc|\n",
      "+-------+---------+--------+--------+\n",
      "+-------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verify delete, should return ZERO records\n",
    "spark.sql(\"SELECT * FROM customer WHERE cust_id = 4 ORDER BY cust_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b19ae-b340-4578-a80c-ae39481fc3b7",
   "metadata": {},
   "source": [
    "## Snapshots\n",
    "### For every DML operation, Iceberg table creates a snapshop, each operation type is captured under \"operation\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5242da9-53cc-4087-9634-8f1d662e7825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:11:45.828440Z",
     "iopub.status.busy": "2022-11-09T12:11:45.827930Z",
     "iopub.status.idle": "2022-11-09T12:11:46.743654Z",
     "shell.execute_reply": "2022-11-09T12:11:46.742256Z",
     "shell.execute_reply.started": "2022-11-09T12:11:45.828410Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "|        committed_at|        snapshot_id|          parent_id|operation|       manifest_list|             summary|\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "|2022-11-09 12:10:...|2174872175979965013|               null|   append|s3://emr-studio-e...|{spark.app.id -> ...|\n",
      "|2022-11-09 12:10:...|2816279682983579927|2174872175979965013|   append|s3://emr-studio-e...|{spark.app.id -> ...|\n",
      "|2022-11-09 12:10:...|7772798101801262353|2816279682983579927|   append|s3://emr-studio-e...|{spark.app.id -> ...|\n",
      "|2022-11-09 12:10:...|5029206383255222294|7772798101801262353|   append|s3://emr-studio-e...|{spark.app.id -> ...|\n",
      "|2022-11-09 12:10:...|7465481207241770807|5029206383255222294|   append|s3://emr-studio-e...|{spark.app.id -> ...|\n",
      "|2022-11-09 12:10:...|2056239600440729870|7465481207241770807|   append|s3://emr-studio-e...|{spark.app.id -> ...|\n",
      "|2022-11-09 12:11:...|5965083993461194125|2056239600440729870|overwrite|s3://emr-studio-e...|{spark.app.id -> ...|\n",
      "|2022-11-09 12:11:...|3528478512288254730|5965083993461194125|   delete|s3://emr-studio-e...|{spark.app.id -> ...|\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\" SELECT * FROM glue_catalog.iceberg_db.customer.snapshots \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23eef2e-fb9a-40cd-bbc3-1a1a7718a1cd",
   "metadata": {},
   "source": [
    "## Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf6c233b-a47c-40da-9953-281dd55c19a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:11:53.076761Z",
     "iopub.status.busy": "2022-11-09T12:11:53.076258Z",
     "iopub.status.idle": "2022-11-09T12:11:55.157519Z",
     "shell.execute_reply": "2022-11-09T12:11:55.156711Z",
     "shell.execute_reply.started": "2022-11-09T12:11:53.076732Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Insert a new record, with time travel we can go back in time when the new record did not exist\n",
    "spark.sql(\"INSERT INTO customer VALUES (7,'Polygon', 60, 'CT')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4da3e2fe-c044-4765-9038-e42601f995e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:13:49.373468Z",
     "iopub.status.busy": "2022-11-09T12:13:49.373069Z",
     "iopub.status.idle": "2022-11-09T12:13:50.256656Z",
     "shell.execute_reply": "2022-11-09T12:13:50.255665Z",
     "shell.execute_reply.started": "2022-11-09T12:13:49.373438Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------+--------+\n",
      "|cust_id|   cust_name|cust_age|cust_loc|\n",
      "+-------+------------+--------+--------+\n",
      "|      1|Prasad Nadig|      25|      NJ|\n",
      "|      2|    Ethereum|      80|      NY|\n",
      "|      3|      Cosmos|      25|      PA|\n",
      "|      4|      Solana|      55|      MD|\n",
      "|      5|     Carnado|      15|      TX|\n",
      "|      6|        Link|      45|      NJ|\n",
      "+-------+------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now let's do a time travel to go back in time before this new record was inserted\n",
    "spark.sql(\" SELECT * FROM customer TIMESTAMP AS OF '2022-11-9 12:11:00' ORDER BY cust_id \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5496ea86-4636-455a-bb7b-7952e8f863e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:14:03.689820Z",
     "iopub.status.busy": "2022-11-09T12:14:03.689134Z",
     "iopub.status.idle": "2022-11-09T12:14:23.026545Z",
     "shell.execute_reply": "2022-11-09T12:14:23.025526Z",
     "shell.execute_reply.started": "2022-11-09T12:14:03.689768Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Update a record\n",
    "spark.sql(\"UPDATE customer SET cust_age = 60 WHERE cust_id = 3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "caee3efe-25b4-4492-a36c-a0fa2545d4f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:14:51.098020Z",
     "iopub.status.busy": "2022-11-09T12:14:51.097508Z",
     "iopub.status.idle": "2022-11-09T12:14:51.615613Z",
     "shell.execute_reply": "2022-11-09T12:14:51.614438Z",
     "shell.execute_reply.started": "2022-11-09T12:14:51.097991Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------+--------+\n",
      "|cust_id|cust_name|cust_age|cust_loc|\n",
      "+-------+---------+--------+--------+\n",
      "|      3|   Cosmos|      25|      PA|\n",
      "+-------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now let's do a time travel to go back in time before this new record was updated to see the old value\n",
    "spark.sql(\" SELECT * FROM customer TIMESTAMP AS OF '2022-11-9 12:14:00' WHERE cust_id = 3 ORDER BY cust_id \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd91f802-aba4-4104-8079-f988eb7174a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:15:00.669867Z",
     "iopub.status.busy": "2022-11-09T12:15:00.669195Z",
     "iopub.status.idle": "2022-11-09T12:15:03.073354Z",
     "shell.execute_reply": "2022-11-09T12:15:03.072289Z",
     "shell.execute_reply.started": "2022-11-09T12:15:00.669816Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Iceberg also allows you to see the deleted records with time travel, let's try it out\n",
    "spark.sql(\"DELETE FROM customer WHERE cust_id = 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "824c24db-7d40-4079-8c5a-614d036965fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:15:20.306378Z",
     "iopub.status.busy": "2022-11-09T12:15:20.305856Z",
     "iopub.status.idle": "2022-11-09T12:15:20.897828Z",
     "shell.execute_reply": "2022-11-09T12:15:20.896998Z",
     "shell.execute_reply.started": "2022-11-09T12:15:20.306347Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------+--------+\n",
      "|cust_id|cust_name|cust_age|cust_loc|\n",
      "+-------+---------+--------+--------+\n",
      "|      2| Ethereum|      80|      NY|\n",
      "+-------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's do a time travel 2 mins backwards from now to see the deleted record still exists in the table\n",
    "spark.sql(\" SELECT * FROM customer TIMESTAMP AS OF '2022-11-9 12:15:00' WHERE cust_id = 2 ORDER BY cust_id \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57a7e347-e9c9-49da-8fc6-4db4d9b2facf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:20:10.724119Z",
     "iopub.status.busy": "2022-11-09T12:20:10.723621Z",
     "iopub.status.idle": "2022-11-09T12:20:23.588465Z",
     "shell.execute_reply": "2022-11-09T12:20:23.587437Z",
     "shell.execute_reply.started": "2022-11-09T12:20:10.724090Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------+--------+\n",
      "|cust_id|   cust_name|cust_age|cust_loc|\n",
      "+-------+------------+--------+--------+\n",
      "|      1|Prasad Nadig|      25|      NJ|\n",
      "|      3|      Cosmos|      60|      PA|\n",
      "|      5|     Carnado|      15|      TX|\n",
      "|      6|        Link|      50|      NJ|\n",
      "|      7|     Polygon|      60|      CT|\n",
      "+-------+------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#in comparison to the above time travel query, lets check the current records in the table, notice cust_id 2 doesnt exists anymore\n",
    "spark.sql(\"SELECT * FROM customer ORDER BY cust_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1669e54-3075-473f-b221-d002f106302d",
   "metadata": {},
   "source": [
    "## Schema Evolution\n",
    "### Add Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c8b1b02-00cf-4dc6-8255-81e890137f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:20:29.269878Z",
     "iopub.status.busy": "2022-11-09T12:20:29.269373Z",
     "iopub.status.idle": "2022-11-09T12:20:30.407711Z",
     "shell.execute_reply": "2022-11-09T12:20:30.406393Z",
     "shell.execute_reply.started": "2022-11-09T12:20:29.269848Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add a new column to iceberg_table table using PySpark\n",
    "spark.sql(\"ALTER TABLE customer ADD COLUMNS (phone_no int)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e069177-3fae-410c-9746-281c8ab45fe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:20:32.744677Z",
     "iopub.status.busy": "2022-11-09T12:20:32.744248Z",
     "iopub.status.idle": "2022-11-09T12:20:32.854133Z",
     "shell.execute_reply": "2022-11-09T12:20:32.853183Z",
     "shell.execute_reply.started": "2022-11-09T12:20:32.744646Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-------+\n",
      "|       col_name|data_type|comment|\n",
      "+---------------+---------+-------+\n",
      "|        cust_id|      int|       |\n",
      "|      cust_name|   string|       |\n",
      "|       cust_age|      int|       |\n",
      "|       cust_loc|   string|       |\n",
      "|       phone_no|      int|       |\n",
      "|               |         |       |\n",
      "| # Partitioning|         |       |\n",
      "|Not partitioned|         |       |\n",
      "+---------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESC TABLE customer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e550e8c5-6a33-40a5-a942-4919842ba76b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:20:35.309678Z",
     "iopub.status.busy": "2022-11-09T12:20:35.309257Z",
     "iopub.status.idle": "2022-11-09T12:20:37.122169Z",
     "shell.execute_reply": "2022-11-09T12:20:37.121136Z",
     "shell.execute_reply.started": "2022-11-09T12:20:35.309646Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Insert new record with a value for Phone_no\n",
    "spark.sql(\"INSERT INTO customer VALUES(8,'Avalanche',20,'NY',1234567890)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4647aecb-f0a8-42fe-b795-232f11db66fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:20:39.474699Z",
     "iopub.status.busy": "2022-11-09T12:20:39.473665Z",
     "iopub.status.idle": "2022-11-09T12:20:40.355248Z",
     "shell.execute_reply": "2022-11-09T12:20:40.353891Z",
     "shell.execute_reply.started": "2022-11-09T12:20:39.474644Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------+--------+----------+\n",
      "|cust_id|   cust_name|cust_age|cust_loc|  phone_no|\n",
      "+-------+------------+--------+--------+----------+\n",
      "|      1|Prasad Nadig|      25|      NJ|      null|\n",
      "|      3|      Cosmos|      60|      PA|      null|\n",
      "|      5|     Carnado|      15|      TX|      null|\n",
      "|      6|        Link|      50|      NJ|      null|\n",
      "|      7|     Polygon|      60|      CT|      null|\n",
      "|      8|   Avalanche|      20|      NY|1234567890|\n",
      "+-------+------------+--------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query customer table and check if the new column was populated\n",
    "spark.sql(\"SELECT * FROM customer ORDER BY cust_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91a671-737c-43ce-bd46-3c4dcfbf93e7",
   "metadata": {},
   "source": [
    "## Rename Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18ac9ee6-15f6-48a5-ba67-e5eec524ac2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:20:45.403464Z",
     "iopub.status.busy": "2022-11-09T12:20:45.402405Z",
     "iopub.status.idle": "2022-11-09T12:20:46.517555Z",
     "shell.execute_reply": "2022-11-09T12:20:46.516762Z",
     "shell.execute_reply.started": "2022-11-09T12:20:45.403383Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename an existing column\n",
    "spark.sql(\"ALTER TABLE customer RENAME COLUMN phone_no TO cust_phone_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f46d1020-4991-47de-b322-962967ae0495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:20:53.437722Z",
     "iopub.status.busy": "2022-11-09T12:20:53.436704Z",
     "iopub.status.idle": "2022-11-09T12:20:53.478052Z",
     "shell.execute_reply": "2022-11-09T12:20:53.476966Z",
     "shell.execute_reply.started": "2022-11-09T12:20:53.437668Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-------+\n",
      "|       col_name|data_type|comment|\n",
      "+---------------+---------+-------+\n",
      "|        cust_id|      int|       |\n",
      "|      cust_name|   string|       |\n",
      "|       cust_age|      int|       |\n",
      "|       cust_loc|   string|       |\n",
      "|  cust_phone_no|      int|       |\n",
      "|               |         |       |\n",
      "| # Partitioning|         |       |\n",
      "|Not partitioned|         |       |\n",
      "+---------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESC TABLE customer\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94224b61-6769-4c58-94d0-e3e53d6a77ce",
   "metadata": {},
   "source": [
    "## Drop Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc7c2f2d-b309-49d0-a7f0-4f0bea1529a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:20:56.320421Z",
     "iopub.status.busy": "2022-11-09T12:20:56.319309Z",
     "iopub.status.idle": "2022-11-09T12:20:57.451211Z",
     "shell.execute_reply": "2022-11-09T12:20:57.449767Z",
     "shell.execute_reply.started": "2022-11-09T12:20:56.320366Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop an existing column, this should drop the column in metadata only\n",
    "spark.sql(\"ALTER TABLE customer DROP COLUMN cust_phone_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eca641c1-c302-4934-a5f3-7416b5f5a1ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:20:59.572926Z",
     "iopub.status.busy": "2022-11-09T12:20:59.572242Z",
     "iopub.status.idle": "2022-11-09T12:20:59.613083Z",
     "shell.execute_reply": "2022-11-09T12:20:59.612297Z",
     "shell.execute_reply.started": "2022-11-09T12:20:59.572856Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-------+\n",
      "|       col_name|data_type|comment|\n",
      "+---------------+---------+-------+\n",
      "|        cust_id|      int|       |\n",
      "|      cust_name|   string|       |\n",
      "|       cust_age|      int|       |\n",
      "|       cust_loc|   string|       |\n",
      "|               |         |       |\n",
      "| # Partitioning|         |       |\n",
      "|Not partitioned|         |       |\n",
      "+---------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESC TABLE customer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27942dd4-b0dd-48b7-abf5-4bfbcbc55485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T12:21:17.143355Z",
     "iopub.status.busy": "2022-11-09T12:21:17.142655Z",
     "iopub.status.idle": "2022-11-09T12:21:18.084594Z",
     "shell.execute_reply": "2022-11-09T12:21:18.083091Z",
     "shell.execute_reply.started": "2022-11-09T12:21:17.143302Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------+--------+----------+\n",
      "|cust_id|   cust_name|cust_age|cust_loc|  phone_no|\n",
      "+-------+------------+--------+--------+----------+\n",
      "|      1|Prasad Nadig|      25|      NJ|      null|\n",
      "|      3|      Cosmos|      60|      PA|      null|\n",
      "|      5|     Carnado|      15|      TX|      null|\n",
      "|      6|        Link|      50|      NJ|      null|\n",
      "|      7|     Polygon|      60|      CT|      null|\n",
      "|      8|   Avalanche|      20|      NY|1234567890|\n",
      "+-------+------------+--------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Similar to record deletion, with time travel we can also see the column that was dropped, pretty powerful isn't it?\n",
    "spark.sql(\" SELECT * FROM customer TIMESTAMP AS OF '2022-11-9 12:21:00' ORDER BY cust_id \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b750db-38ac-4df1-beb3-240ddf866407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Kubernetes)",
   "language": "python",
   "name": "spark_python_kubernetes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
